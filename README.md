# ğŸ›’ Retail Sales Data Analysis with SQL and Python

## ğŸ“Œ Project Overview
This project demonstrates an end-to-end **Retail Sales Data Analysis** workflow using **Python, Pandas, Matplotlib, and Spark SQL** on **Databricks Community Edition**.

The goal is to simulate a real-world data analytics and data engineering use case by:
- Generating synthetic retail transaction data
- Cleaning and transforming data using Pandas
- Visualizing sales trends using Matplotlib
- Performing advanced analytics using Spark SQL
- Applying optimized aggregations and window functions

---

## ğŸ§° Tech Stack
- **Python 3**
- **Pandas & NumPy**
- **Matplotlib**
- **Apache Spark (Spark SQL)**
- **Databricks Community Edition**

---

## ğŸ“‚ Dataset
Synthetic retail transaction data generated within the notebook.

**Columns:**
- TransactionID
- Date
- Product
- Category
- Region
- Quantity
- Price
- CustomerID
- TotalSales (derived)

Includes **dirty data** such as:
- Missing values
- Duplicate records

---

## ğŸ”„ Data Pipeline Flow
1. Data Generation (Python)
2. Data Cleaning & Transformation (Pandas)
3. Exploratory Data Analysis (Matplotlib)
4. SQL Analytics (Spark SQL)
5. Optimized Aggregations using Window Functions

---

## ğŸ“Š Key SQL Insights
- Top-selling products by revenue
- Regional sales performance
- Monthly revenue trends
- Product ranking within regions using window functions

---

## ğŸš€ How to Run
1. Open **Databricks Community Edition**
2. Create a new Python notebook
3. Copy-paste notebook cells from this repository
4. Run sequentially

---


## ğŸ“ˆ Future Enhancements
- Delta Lake implementation
- Incremental data loads
- Dashboard using Power BI / Tableau
- Orchestration with Airflow

---

â­ If you like this project, give it a star!
